{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cached RAG using Amazon Opensearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade langchain langchain-core langchain-aws langchain-community boto3 sagemaker pydantic opensearch-py  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import json\n",
    "import boto3\n",
    "import numpy as np\n",
    "from langchain_aws import BedrockEmbeddings\n",
    "from langchain_community.vectorstores import OpenSearchVectorSearch\n",
    "from opensearchpy import OpenSearch, RequestsHttpConnection, AWSV4SignerAuth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Create bedrock client and initialize claude llm\n",
    "BEDROCK_CLIENT = boto3.client(\"bedrock-runtime\", 'us-east-1')\n",
    "llm = ChatBedrock( model_kwargs={\"max_tokens\":2048,\"temperature\":0.5,\"top_k\":50,\"anthropic_version\":\"bedrock-2023-05-31\"},\n",
    "      model_id=\"us.anthropic.claude-3-5-sonnet-20241022-v2:0\",\n",
    "      client=BEDROCK_CLIENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize Cohere embeddings\n",
    "embeddings = BedrockEmbeddings(client=BEDROCK_CLIENT,model_id=\"cohere.embed-english-v3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Using local cache(python dictionary), we can use Valkey or Redis cache\n",
    "response_cache = {}\n",
    "embedding_cache = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Initialize Opensearch Client\n",
    "oss_host = \"search-xxxxxxxxxxxxxxxxxxxxxxx.us-east-.es.amazonaws.com\"\n",
    "credentials = boto3.Session().get_credentials()\n",
    "region = \"us-east-1\"\n",
    "auth = AWSV4SignerAuth(credentials, region, \"es\")\n",
    "os_client = OpenSearch(\n",
    "    hosts = [{'host':oss_host, 'port':443}],\n",
    "    http_auth = auth,\n",
    "    use_ssl = True,\n",
    "    verify_certs = True,\n",
    "    connection_class = RequestsHttpConnection,\n",
    "    pool_maxsize = 60\n",
    ")\n",
    "os_client.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Provide a name for your index\n",
    "index_name = 'cached-rag-index'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "#Create index\n",
    "index_body = {\n",
    "    \"settings\":{\n",
    "        \"index\":{\n",
    "            \"knn\": True,\n",
    "            \"knn.algo_param.ef_search\": 256\n",
    "        }\n",
    "    },\n",
    "    \"mappings\":{\n",
    "        \"properties\":{\n",
    "            \"vector_field\":{\n",
    "                \"type\": \"knn_vector\",\n",
    "                \"dimension\": 1024,\n",
    "                \"method\":{\n",
    "                    \"name\":\"hnsw\",\n",
    "                    \"space_type\": \"l2\",\n",
    "                    \"engine\": \"nmslib\",\n",
    "                    \"parameters\": {\n",
    "                        \"ef_construction\": 256,\n",
    "                        \"m\":32\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }    \n",
    "}\n",
    "\n",
    "response = os_client.indices.create(index_name, body=index_body)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def extract_paragraphs(file_path: str) -> list:\n",
    "    # Open the file and read its contents\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "    \n",
    "    # Split the text by double newlines to separate paragraphs\n",
    "    paragraphs = [para.strip() for para in text.split('\\n\\n') if para.strip()]\n",
    "    \n",
    "    return paragraphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "file_path = 'your-file.txt' # your file path \n",
    "paragraphs = extract_paragraphs(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "opensearch_vector_search = OpenSearchVectorSearch.from_texts(\n",
    "        paragraphs,\n",
    "        embeddings,\n",
    "        opensearch_url=f'https://{oss_host}:443',\n",
    "        http_auth=auth,\n",
    "        use_ssl = True,\n",
    "        verify_certs = True,\n",
    "        connection_class=RequestsHttpConnection,\n",
    "        index_name=index_name,\n",
    "        timeout=60,\n",
    "        bulk_size=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def search_similar_cached_query(new_embedding, threshold=0.80):\n",
    "    best_match = None\n",
    "    best_similarity = 0\n",
    "\n",
    "    for cached_query, cached_embedding in embedding_cache.items():\n",
    "        similarity = cosine_similarity(new_embedding, cached_embedding)\n",
    "        print(f\"Comparing: {cached_query} with similarity: {similarity}\")\n",
    "\n",
    "        # If similarity is above the threshold and better than the previous best match, store it\n",
    "        if similarity >= threshold and similarity > best_similarity:\n",
    "            best_match = cached_query\n",
    "            best_similarity = similarity\n",
    "\n",
    "    return best_match  # Returns the cached query key if found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(vec1, vec2):\n",
    "    \"\"\"Compute cosine similarity between two vectors.\"\"\"\n",
    "    return np.dot(vec1, vec2) / (np.linalg.norm(vec1) * np.linalg.norm(vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def search_opensearch(index: str, query: str):\n",
    "    \"\"\"Perform k-NN search in OpenSearch using OpenSearchVectorSearch.\"\"\"\n",
    "    query_embedding = embeddings.embed_query(query)  # Get the 1024-dimensional embedding for the query\n",
    "\n",
    "    search_query = {\n",
    "        \"size\": 2,\n",
    "        \"query\": {\n",
    "            \"knn\": {\n",
    "                \"vector_field\": {\n",
    "                    \"vector\": query_embedding,\n",
    "                    \"k\": 5\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Perform the query on OpenSearch\n",
    "    response = os_client.search(index=index, body=search_query)\n",
    "    results = response[\"hits\"][\"hits\"]\n",
    "    \n",
    "    return results, query_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "def cache_augmented_search(index: str, query: str):\n",
    "    \"\"\"Search OpenSearch with an embedding-based cache.\"\"\"\n",
    "    query_embedding = embeddings.embed_query(query)\n",
    "\n",
    "    # Step 1: Check cache for similar query\n",
    "    cached_key = search_similar_cached_query(query_embedding)\n",
    "\n",
    "    if cached_key and cached_key in response_cache:  \n",
    "        print(\"Cache hit! Returning similar cached results.\")\n",
    "        return response_cache[cached_key]\n",
    "\n",
    "    # Step 2: If no match, query OpenSearch\n",
    "    print(\"Cache miss. Querying OpenSearch...\")\n",
    "    results, new_embedding = search_opensearch(index, query)\n",
    "\n",
    "    # Step 3: Store new embedding & results in cache\n",
    "    response_cache[query] = results\n",
    "    embedding_cache[query] = new_embedding\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "query_text = \"your question\"\n",
    "results = cache_augmented_search(index_name, query_text)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
